{"cells":[{"cell_type":"markdown","metadata":{"id":"cPellXKN7Nbw"},"source":["# HW2-1: Convoultional Neural Network : CIFAR-10 (pytorch)\n","Now, we will implement more complex CNN architecture by using pytorch and run it with GPU.\n","- Here, we will implement\n","  1) Convolution neural network with pytorch\n","  2) Training neural networks with above implementation\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20476,"status":"ok","timestamp":1697618269182,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"vPi7eJxJ7PzV","outputId":"f6328a76-5ef4-4cfa-8252-35c4148dd422"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/your_directory')\n","\n","import os\n","os.chdir('/content/drive/My Drive/your_directory')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10052,"status":"ok","timestamp":1697618279230,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"T1kC94307Nbz"},"outputs":[],"source":["import torch\n","import torchvision.transforms as transforms\n","\n","import numpy as np\n","from utils import *\n","from HW_YourAnswer_cnn import *"]},{"cell_type":"markdown","metadata":{"id":"GBeOuAoU7Nb0"},"source":["## Set Random Seed"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1697618279231,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"Sblbzm_o7Nb0"},"outputs":[],"source":["seed = 0\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{},"source":["## Use GPU"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"qfSYBZ_j7Nb0"},"source":["## Data Preprocessing\n","### CIFAR-10 dataset\n","We will use CIFAR-10 dataset\n","- The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class.\n","- We will use 10000 training images and 1000 test images as we did in HW 2-1.\n"]},{"cell_type":"markdown","metadata":{},"source":["### Define transformation\n","To augment the dataset, we will use torchvision.transforms.Compose function. \n","\n","Various data augmentation techniques (resize, crop, flip, contrast, ...) can be used. \n","\n","Here, we will use simple data augmentations:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n"]},{"cell_type":"markdown","metadata":{},"source":["## Define custom dataset and loader"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","from torch.utils.data import Dataset, DataLoader\n","\n","class CustomCIFAR10 (Dataset):\n","    def __init__(self,  mode, transform):\n","        self.mode = mode\n","        self.transform = transform\n","        \n","        raw_data= get_CIFAR10_data(subtract_mean=False)\n","        if self.mode == 'train':\n","            # (10000, 32, 32, 3), (10000,)\n","            self.data, self.target = raw_data[\"X_train\"],raw_data[\"y_train\"]\n","        elif self.mode == 'test':\n","            # (1000, 32, 32, 3), (1000,)\n","            self.data, self.target = raw_data[\"X_test\"],raw_data[\"y_test\"]\n","        else:\n","            raise NotImplementedError\n","        \n","        assert len(self.data) == len(self.target), \"Number of data and target should be same!\"\n","\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        # dtype of image and label is numpy\n","        image, label = self.data[idx], self.target[idx]\n","        image = Image.fromarray(image.astype(np.uint8))\n","        \n","        if self.transform is not None:\n","            image = self.transform(image)\n","\n","        return image, label\n","    \n","def CIFAR10_dataloader(batch_size, train_transform, test_transform):\n","        \n","        train_dataset = CustomCIFAR10(mode='train', transform=train_transform)\n","        test_dataset = CustomCIFAR10(mode='test', transform=test_transform)\n","                \n","        train_datalader = DataLoader(train_dataset,\n","                                     batch_size=batch_size,\n","                                     shuffle=True)\n","        \n","        test_datalader = DataLoader(test_dataset,\n","                                     batch_size=1,\n","                                     shuffle=False)\n","        classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","        return train_datalader, test_datalader, classes\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# data loader\n","batch_size = 32\n","trainloader, testloader, classes  = CIFAR10_dataloader(batch_size,transform_train,transform_test)"]},{"cell_type":"markdown","metadata":{"id":"ZwRHuq577Nb1"},"source":["## Visualize training images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807},"executionInfo":{"elapsed":1323,"status":"ok","timestamp":1697618289757,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"vaawaoHv7Nb1","outputId":"8f1f0d93-79f7-4c2e-edef-3c952c27b4d4"},"outputs":[],"source":["iterator = iter(trainloader)\n","sample_image, sample_label = next(iterator)\n","\n","import torchvision\n","imshow(torchvision.utils.make_grid(sample_image,8))"]},{"cell_type":"markdown","metadata":{"id":"Dh4fiTc97Nb2"},"source":["### To Do: Implement pytorch_CNN\n","- Implement convolutional neural networks with pytorch (See details in `HW_YourAnswer_cnn.py`) .\n","    - Feature Extraction Layer Block\n","      - first layer: Conv, Batchnorm, Relu, Max pool\n","      - second layer:  Conv, Batchnorm, Relu, Max pool\n","    - Classification Layer Block\n","      - first layer: Linear, Relu\n","      - second layer: Linear, Relu\n","      - last layer: Linear\n","- You will implement __init__() and __forward__() function using torch.nn module.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5568,"status":"ok","timestamp":1697618295321,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"zteEeMRq7Nb2","outputId":"e3521674-a0f6-4a2d-c23c-ccccf853b878"},"outputs":[],"source":["num_classes=len(classes)\n","net = pytorch_CNN(num_classes)\n","net.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["## Setting Hyperparameters\n","Here, we manually set hyperparameters(epochs, lr, ..) that are used for training the model. Hyper-parameters are one of the important factor to train a model up to targeting performance. "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1697618295322,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"hrYPQy227Nb2"},"outputs":[],"source":["epochs = 20\n","learning_rate=0.001\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{},"source":["### Let's training and check the results\n","\n","You will achieve greater than 55% acccuracy on the training set."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import time\n","start = time.time()\n","start_epoch = 0 \n","\n","\n","tr_acc = []\n","tr_loss = []\n","te_acc = []\n","te_loss = []\n","\n","for epoch in range(epochs):\n","    net.train()\n","    train_loss = 0\n","    train_correct = 0\n","    test_correct = 0\n","    \n","    for batch_idx, (images, labels) in enumerate(trainloader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = net(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","        _, predicted = outputs.max(1)\n","        train_correct += predicted.eq(labels).sum().item()\n","\n","    tr_loss_i = train_loss/len(trainloader)\n","    tr_acc_i = 100.*train_correct/len(trainloader.dataset)\n","    \n","    # eval\n","    net.eval()\n","    test_loss = 0\n","    \n","    with torch.no_grad():\n","        for batch_idx, (images, labels) in enumerate(testloader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = net(images)\n","\n","            loss = criterion(outputs, labels)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            test_correct += predicted.eq(labels).sum().item()\n","\n","    te_loss_i = test_loss/len(testloader)\n","    te_acc_i = 100.*test_correct/len(testloader.dataset)\n","    \n","    print(f'Epoch: {epoch}, Training loss: {tr_loss_i:.3f}, Training acc: {tr_acc_i:.3f},  Test loss: {te_loss_i:.3f}, Test acc : {te_acc_i:.3f}')\n","    \n","    tr_loss.append( tr_loss_i )\n","    tr_acc.append ( tr_acc_i )\n","    te_loss.append(te_loss_i )\n","    te_acc.append(te_acc_i )\n","    \n","    \n","#Time Calculation\n","\n","finish = time.time() - start\n","temp_log = \"Time Elapse: %s\" %(format_time(finish))\n","print(temp_log)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":525},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1697618614191,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"sIcujRBT7Nb4","outputId":"65416341-ba75-4230-ff23-0de5e5aaf4a8"},"outputs":[],"source":["loss_and_acc(tr_acc, tr_loss, 'Train')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":525},"executionInfo":{"elapsed":1225,"status":"ok","timestamp":1697618615412,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"CGr_egCz7Nb4","outputId":"56c4287e-dd40-443d-9c67-c3002e6bb227"},"outputs":[],"source":["loss_and_acc(te_acc, te_loss, 'Test')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1697618615412,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"l2xoqAi67Nb4","outputId":"13ef75ca-f855-4670-ae38-a16b976672b7"},"outputs":[],"source":["print('The best test accuracy :', np.max(te_acc), 'at epoch', np.argmax(te_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-5VT40lh8EGK"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"nbformat":4,"nbformat_minor":0}
