{"cells":[{"cell_type":"markdown","metadata":{"id":"yxTexBul1oAw"},"source":["# HW2-1: Convolutional neural networks (numpy)\n","In this exercise, we will implement several layer types that are used in convolutional networks.\n","You will be asked to complete several functions/classes used below in `HW_YourAnswer.py`.\n","- Convolution forward / backward\n","- (Max / Average) Pooling forward / backward\n","- Batch normalization (for CNN) forward / backward\n","\n","You will then use these layers to train a three-layer convolutional network on the CIFAR-10 dataset  in `HW_YourAnswer_cnn.py`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2220,"status":"ok","timestamp":1697618428530,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"OTvjt1-a1oAy","outputId":"1bc2ef4f-47e9-4f48-de96-55a03a866557"},"outputs":[],"source":["#Colab setting cell\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/your_directory')\n","\n","import os\n","os.chdir('/content/drive/My Drive/your_directory')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2124,"status":"ok","timestamp":1697618430652,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"o3zSol-p1oAz","tags":["pdf-ignore"]},"outputs":[],"source":["# Setup cell.\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython import display\n","\n","\n","from utils import *\n","from HW_YourAnswer import *\n","from HW_YourAnswer_cnn import *\n","\n","%matplotlib inline\n"]},{"cell_type":"markdown","metadata":{"id":"DQ0tVmuB1oA0"},"source":["# Exercise 1: Convolution layer\n","\n","## Exercise 1.1: forward pass of convolution layer\n","\n","We will implement forward pass of convolution layer:\n"," 1. consider input data of shape (N, H, W, C) and filter of shape (F, FH, FW, C)\n","\n","    N: the number of input, H: height of input, W: width of input, C: channel\n","    \n","    F: the number of filter, FH: height of filter, FW: width of filter, C: filter channel\n","\n","    \n"," 2. consider zero-padding, stride, and bias.\n","\n","\n","\n","<img src=\"https://github.com/csaybar/DLcoursera/blob/master/Convolutional%20Neural%20Networks/week01/images/Convolution_schematic.gif?raw=1\" style=\"width:500px;height:300px;\">\n","\n","**Simple example of convolution operation**<br> with a filter of 3x3 (no bias term), no zero-padding, and a stride of 1  \n","\n","\n","#### For this, we will learn and implement **helpful functions** first.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3bDsj9Wl1oA0"},"source":["### 1) Zero-Padding\n","\n","Before implementing it, let's learn about numpy.pad function.\n","\n","Zero-padding adds zeros around the border of an image ( Image (3 channels, RGB) with a pad=2 case):\n","\n"," <img src=\"https://github.com/csaybar/DLcoursera/blob/master/Convolutional%20Neural%20Networks/week01/images/PAD.png?raw=1\" style=\"width:600px;height:400px;\">\n","\n","\n","\n","We will use 'pad' function in numpy library (https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html).\n","\n","if you want to pad the array with a different padding size for each dimension, for example padding size 1 for 2nd dimension, 3 for 4th dimension, and no padding for the rest, use following commands:\n","```python\n","arr = np.pad(arr, ((0,0), (1,1), (0,0), (3,3), (0,0)), 'constant', constant_values = (..,..))\n","```\n","Note that default padding value is 0 if mode is ‘constant’ and we use default constant_values.\n","\n","For further description, please read : https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html"]},{"cell_type":"markdown","metadata":{"id":"DjTSpuSV1oA0"},"source":["Let's check with simple example.\n","\n","- x: input data of shape (N, H, W, C)\n","- pad: the number of pixels for padding.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1697618430653,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"oY74QAXY1oA1","outputId":"540ce700-b1fe-4ead-fef3-ab303a5ac410"},"outputs":[],"source":["\n","# 1 x 4 x 4 x 1 example, pad=1\n","pad=1\n","original_matrix= np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])\n","original_matrix=np.expand_dims(original_matrix,axis=(0,-1))\n","\n","# Shape of original matrix:  (1, 4, 4, 1)\n","print(\"arr shape: \", original_matrix.shape)\n","\n","padded_matrix =np.pad(original_matrix, ((0, 0),  (pad, pad), (pad, pad), (0, 0)), mode='constant')\n","print(\"original matrix:\\n\",original_matrix[0,:,:,0])\n","print(\"padded matrix:\\n\", padded_matrix[0,:,:,0])"]},{"cell_type":"markdown","metadata":{"id":"nJj6p-T51oA1"},"source":["### 2) Find the receptive field\n","\n","Here, we implement extracting the receptive field or region of interest (ROI) from the **single** input tensor `x` for a given position (i, j) in the output feature map `O`.\n","\n","This ROI is the area that the filter w will overlap during the convolution process.\n","\n","Given a specific position (i, j) in the output feature map, the function determines and extracts this region from the input tensor.\n","\n","Below image will help understanding.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1697618430653,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"D22ZWvWX1oA1","outputId":"5b0837a3-fa6d-4e0e-d1c9-fc973c94118a"},"outputs":[],"source":["display.Image(\"figures/roi.png\",width=500,height=300)\n"]},{"cell_type":"markdown","metadata":{"id":"uL-v-CyI1oA2"},"source":["\n","Input: x,i,j,FH,FW,stride\n","  - x (numpy.ndarray): **Single** input tensor with shape (H, W, C), where:\n","      * H is the height of the input.\n","      * W is the width of the input.\n","      * C is the number of channels.\n","  - i (int): Vertical index representing the number of strides taken along the height of the input.\n","  - j (int): Horizontal index representing the number of strides taken along the width of the input.\n","  - FH (int): Height of the convolutional filter.\n","  - FW (int): Width of the convolutional filter.\n","  - stride (int): The step size at which the input is sampled for convolution.\n","\n","Output: \n","  - out: The receptive field with shape (FH, FW, C) from the input tensor `x` for a given position (i, j) in the output feature map."]},{"cell_type":"markdown","metadata":{"id":"_QZk-R4I1oA2"},"source":["### To Do:\n","- Implement  `Conv._find_roi` function in `HW_YourAnswer.py` file\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EVcicmsj1oA2"},"source":["Let's check with simple example which is the same as above figure\n","\n","Here,\n","- x is shape of (4,4,1)\n","- w is shape of (2,2,1), thus, FH=2, FW=2\n","- stride=1\n","- no zero-padding\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zYmFnvWz1oA2"},"source":["Let's check your implementation with above figure.\n","\n","Here, we will get the corresponding receptive fields for for a given position (1, 2) and (2,1) in the output feature map.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1697618430653,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"wZ97J8v41oA2","outputId":"04b2c999-b828-47d5-d0ae-a842de104142"},"outputs":[],"source":["input_matrix= np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])\n","input_matrix=np.expand_dims(input_matrix,axis=(-1))\n","\n","stride=1\n","w= np.array([[1,0],[-1,1]])\n","w=np.expand_dims(w,axis=(-1))\n","\n","# Shape of original matrix\n","print(\"input_matrix shape: \")\n","print( input_matrix.shape)\n","print(\"input_matrix: \")\n","print(input_matrix[:,:,0])\n","\n","print(\"w shape: \")\n","print(w.shape)\n","print(\"w: \")\n","print(w[:,:,0])\n","\n","\n","# Output should be [[ 7  8]\n","#                    [11 12]]\n","print('Receptive field of convolved output at location (1,2) : ')\n","i,j,FH,FW,stride=1,2,2,2,1\n","roi = Conv._find_roi(input_matrix,i,j,FH,FW,stride)\n","print(roi[:,:,0])\n","\n","\n","# Output should be [[10 11]\n","#                    [14 15]]\n","print('Receptive field of convolved output at location (2,1) : ')\n","i,j=2,1\n","roi = Conv._find_roi(input_matrix,i,j,FH,FW,stride)\n","print(roi[:,:,0])\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9HzTTkX11oA3"},"source":["### 3) Implement forward pass of convolution layer\n","Using above two functions, we will implement forward pass of convolution layer  \n","\n","**Hint**:\n","The main point of implementation for convolution forward pass:\n","\n","  Step-1: First, extract local region (receptive filed) of input  (Use `Conv._find_roi` function)\n","    \n","  Step-2: Do element-wise multiplication in numpy '*' with local region and filter, and then calculate the sum.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":949,"status":"ok","timestamp":1697618431598,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"bEICqvgu1oA3","outputId":"298608f1-6cab-46c5-8345-497dab2a5f72"},"outputs":[],"source":["display.Image(\"figures/cnn_hint.png\",width=500,height=300)"]},{"cell_type":"markdown","metadata":{"id":"Kcr-ZIqq1oA3"},"source":["\n","(For simplicity, the bias term is omitted in this figure)\n","\n","### To Do:\n","- Implement forward pass of convolution layer (`Conv.naive_forward` function in `HW_YourAnswer.py` file) <br>\n","- Here, we restrict your implementation. You should use `Conv._find_roi` function when implementing `Conv.naive_forward` function.\n","- You do not have to consider computational efficiency."]},{"cell_type":"markdown","metadata":{"id":"SXbNlrD-1oA3"},"source":["Let's check with simple case. (Same as the above figure)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1697618431598,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"uApQwjpA1oA3","outputId":"2b02e83f-902b-4f23-bb85-3d7e5542de5e"},"outputs":[],"source":["# Define a single 4x4 image, single channel\n","# Data format\n","# x: Input data of shape (H, W, C), here, (3,3,1)\n","# w:  Filter weights of shape (FH, FW, C), here, (2,2,1)\n","\n","x=np.array([[2,4,7],[3,2,1],[1,3,9]])\n","x=np.expand_dims(x,axis=(0,-1))\n","print(\"shape of x: \")\n","print(x.shape)\n","\n","w=np.array([[1,0],[-1,1]])\n","w=np.expand_dims(w,axis=(0,-1))\n","print(\"shape of w: \")\n","print(w.shape)\n","\n","# We did not consider bias and zero-padding. stride is set for 1\n","b = np.array([0])\n","conv_param = {'stride': 1, 'pad': 0}\n","\n","\n","out,_ = Conv.naive_forward(x, w,b,conv_param)\n","\n","\n","print(\"\\nConvolved Output:\")\n","print(out[0,:,:,0])\n","\n","# The output will be [[1. 3.]\n","#                     [5. 8.]]\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RjAqrCtm1oA4"},"source":["Let's check your implementation with more general case."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1697618431598,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"e9rT3wLK1oA4","outputId":"92e49bd2-465d-4ee1-ad1c-53c09f0515ba"},"outputs":[],"source":["x_shape = (2, 4, 4, 3)\n","w_shape = (3, 4, 4, 3)\n","x = np.linspace(-0.1, 0.9, num=np.prod(x_shape)).reshape(x_shape)\n","w = np.linspace(-0.1, 0.5, num=np.prod(w_shape)).reshape(w_shape)\n","b = np.linspace(-0.2, 0.3, num=3)\n","conv_param = {'stride': 2, 'pad': 1}\n","\n","out, _ = Conv.naive_forward(x, w, b, conv_param)\n","correct_out = np.array([[[[-0.02202061,  0.60003681,  1.22209422],\n","   [-0.03036805,  0.76340817,  1.55718439]],\n","  [[-0.18419948,  1.12473316 , 2.43366581],\n","   [-0.27840633,  1.20224512,  2.68289658]]],\n"," [[[ 0.38819654,  3.75775488,  7.12731321],\n","   [ 0.20813029,  3.74940743,  7.29068458]],\n","  [[-0.46085756 , 3.595576 ,   7.65200957],\n","   [-0.72678322,  3.50136916 , 7.72952153]]]])\n","\n","# Your output (difference) should be around e-8\n","print('Testing conv_forward_naive')\n","print('difference: ', rel_error(out, correct_out))\n"]},{"cell_type":"markdown","metadata":{"id":"ByktohOK1oA4"},"source":["## Exercise 1.2: efficient forward pass of convolutional layer\n","\n","\n","In the previous implementation of `Conv.naive_forward` function, we did not care about computational inefficiency.\n","\n","The simple naive implementation would require four for-loops (over N, H', W', F) where H'=output feature map height, W'=output feature map width\n","\n","We can accelerate it by utilizing below `im2col` concept.\n","\n","This implementation helps to remove the for-loop related to the filter size (F).\n","\n","You can make the implementation more efficiently by also removing the other for-loops, but we only consider about removing the for-loop related to the filter size (F).\n","\n","**Hint**: the main point of implementation for efficient convolution operation:  `im2col`\n","\n","  Specifically,\n","  - Input matrix and filter matrix into columns, which can help to vectorize operations.\n","  - For the input matrix, extract the receptive fields (roi), vectorize them, and make those columns into single matrix\n","  - Then, do dot product using two matrix\n","\n","See the below figure for better understanding. This process is called image to column (`im2col`).\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1697618431598,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"URskOOph1oA4","outputId":"a23ce4d3-87d3-4adf-d58e-6adc828facb8"},"outputs":[],"source":["from IPython.display import Image\n","display.Image(\"figures/im2col.png\",width=500,height=300)"]},{"cell_type":"markdown","metadata":{"id":"OZDlgeHY1oA4"},"source":["Note that this concept can be used not only in the forward pass but also in the backward pass.\n"]},{"cell_type":"markdown","metadata":{"id":"ZBDfGzyq1oA5"},"source":["In order to vectorize the matrix or tensor, you can use numpy.reshape function (https://numpy.org/doc/stable/reference/generated/numpy.reshape.html).\n","\n","Here is the example."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1697618431598,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"BDuNT5AF1oA5","outputId":"2b04e7a1-6363-4ada-c268-93af2f054b86"},"outputs":[],"source":["image = np.array([\n","    [2,4],\n","    [3,2]\n","])\n","filter = np.array([\n","    [1,0],\n","    [-1,1]\n","])\n","\n","print ('image: ', image.reshape(1,-1))\n","print('filter: ', filter.reshape(1,-1))\n","print ('elementwise multiplication of image and filter: ', image.reshape(1,-1)* filter.reshape(1,-1) )\n"]},{"cell_type":"markdown","metadata":{"id":"tjj5GdEh1oA5"},"source":["### To Do:\n","- Implement efficient version of convolution layer (`Conv.forward` function in `HW_YourAnswer.py` file) <br>\n","- Here, we restrict your implementation. You should use `Conv._find_roi` function when implementing `Conv.forward` function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1697618431598,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"PDzmHS0Q1oA5","outputId":"6b6a6a4c-f0a8-4253-bb52-5eab57875d0c"},"outputs":[],"source":["x_shape = (2, 4, 4, 3)\n","w_shape = (3, 4, 4, 3)\n","x = np.linspace(-0.1, 0.9, num=np.prod(x_shape)).reshape(x_shape)\n","w = np.linspace(-0.1, 0.5, num=np.prod(w_shape)).reshape(w_shape)\n","b = np.linspace(-0.2, 0.3, num=3)\n","conv_param = {'stride': 2, 'pad': 1}\n","\n","out, _ = Conv.forward(x, w, b, conv_param)\n","correct_out = np.array([[[[-0.02202061,  0.60003681,  1.22209422],\n","   [-0.03036805,  0.76340817,  1.55718439]],\n","  [[-0.18419948,  1.12473316 , 2.43366581],\n","   [-0.27840633,  1.20224512,  2.68289658]]],\n"," [[[ 0.38819654,  3.75775488,  7.12731321],\n","   [ 0.20813029,  3.74940743,  7.29068458]],\n","  [[-0.46085756 , 3.595576 ,   7.65200957],\n","   [-0.72678322,  3.50136916 , 7.72952153]]]])\n","\n","# Your output (difference) should be around e-8\n","print('Testing conv_forward')\n","print('difference: ', rel_error(out, correct_out))"]},{"cell_type":"markdown","metadata":{"id":"YSPrXIvT1oA5"},"source":["### Time check\n","\n","Here is the time difference with our (for-loop based) naive version implementation.\n","\n","(We use four for-loops (over N, H', W', F) for the naive implementation. )\n","\n","Your implementation should be at least 20x faster than our naive for-loop based implementation.\n","\n","As mentioned before, avoiding the looping over the number of filter (F) is the main point here.\n","\n","Thus, you do not have to consider other options for further accelerating the computation. (For this, much more complex implementation would be required)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8561,"status":"ok","timestamp":1697618440156,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"tbDeIKXo1oA5","outputId":"3b147825-7f49-4874-bb58-876249ac17bc"},"outputs":[],"source":["from time import time\n","from comparison import naive_forward\n","np.random.seed(231)\n","x = np.random.randn(100, 31, 31,3)\n","w = np.random.randn(25, 3, 3, 3)\n","b = np.random.randn(25,)\n","dout = np.random.randn(100, 16, 16,25)\n","conv_param = {'stride': 2, 'pad': 1}\n","\n","t0 = time()\n","out_naive, cache_naive = naive_forward(x, w, b, conv_param)\n","t1 = time()\n","out_fast, cache_fast = Conv.forward(x, w, b, conv_param)\n","t2 = time()\n","\n","print('Testing conv_forward_fast:')\n","print('Naive: %fs' % (t1 - t0))\n","print('Fast: %fs' % (t2 - t1))\n","print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n","print('Difference: ', rel_error(out_naive, out_fast))"]},{"cell_type":"markdown","metadata":{"id":"omd8cC9V1oA6"},"source":["## Exercise 2.2: backward pass of convolutional layer\n","\n","Now, we will implement the backward pass of convolution layer.\n","\n","We suggest some hints for implementing them.\n","\n","We consider simple case.\n","\n","- Input x shape of 3 X 3\n","\n","- Filter w shape of 2 X 2\n","\n","- Thus, output O is shape of 2 X 2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1697618440156,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"I4EtkTl61oA6","outputId":"c133e09f-2edc-4d5d-8540-9d6d1089a443"},"outputs":[],"source":["display.Image(\"figures/backward_1.png\",width=900,height=500)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1697618440156,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"t_kPklJc1oA6","outputId":"ac39ad07-44bd-4a2b-ee23-86ff656150c4"},"outputs":[],"source":["display.Image(\"figures/backward_2.png\",width=900,height=500)"]},{"cell_type":"markdown","metadata":{"id":"GMHsdpOV1oA7"},"source":["In Lecture 7, we individually computed  each element of a gradient matrix, denoted as the gradient of 𝐹_𝑖𝑗, (figure (a))).\n","\n","However, this approach can become intricate when the stride exceeds 1, necessitating the use of dilated convolution.\n","\n","From an implementation standpoint, it's more straightforward to compute the entire gradient matrix at once by leveraging intermediate results, as illustrated in figure (b).\n","\n","Specifically, we start by computing the values for each of the four boxes (colored as red, green, purple, and blue) and subsequently aggregate them while preserving their respective positions.\n","\n","(How to calculate each boxes are presented in figure (d))\n","\n","Then, as described in (c), we can get the same result with (a).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697618440156,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"x9xtKUNn1oA7","outputId":"ed87c90d-b132-4119-fcd7-bc6799cf9952"},"outputs":[],"source":["display.Image(\"figures/backward_3.png\",width=900,height=600)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1697618440156,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"f-yCs9jf1oA7","outputId":"fee80a14-5453-469c-836f-bfd6de33d248"},"outputs":[],"source":["display.Image(\"figures/backward_4.png\",width=800,height=600)"]},{"cell_type":"markdown","metadata":{"id":"yM0o6FfQ1oA8"},"source":["As can be verified in the figure (d), this process has the exact same order with the forward pass of convolution layer.\n","(Namely, the cases where stride (>1) are inherently considered. )\n","\n","Note that element-wise multiplication (not dot product) is applied in (d) step.\n","\n","This trick can also be utilized similariy when implementing the gradients (w.r.t. input)."]},{"cell_type":"markdown","metadata":{"id":"wxBV_8iH1oA8"},"source":["\n","### To Do:\n","- Implement the backward pass for the convolution operation in the `Conv.backward` function in `HW_YourAnswer.py`.\n","\n","Here, you do not have to consider computational efficiency here. \n","\n","But, if you could implement more efficiently by using similar concept described in Exercise 1.2, you have a chance to get a bonus point. \n","\n","Refer to Exercise 4 for more information on earning a bonus point.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":573,"status":"ok","timestamp":1697618440724,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"UbgCU9c51oA8","outputId":"13644fea-dec5-4070-9f17-8ebcc2e37e46"},"outputs":[],"source":["np.random.seed(231)\n","x = np.random.randn(4, 5, 5, 3)\n","w = np.random.randn(2, 3, 3, 3)\n","b = np.random.randn(2,)\n","dout = np.random.randn(4, 5, 5, 2)\n","conv_param = {'stride': 1, 'pad': 1}\n","\n","dx_num = eval_numerical_gradient_array(lambda x: Conv.forward(x, w, b, conv_param)[0], x, dout)\n","dw_num = eval_numerical_gradient_array(lambda w: Conv.forward(x, w, b, conv_param)[0], w, dout)\n","db_num = eval_numerical_gradient_array(lambda b: Conv.forward(x, w, b, conv_param)[0], b, dout)\n","\n","out, cache = Conv.forward(x, w, b, conv_param)\n","dx, dw, db = Conv.backward(dout, cache)\n","\n","# Your errors should be around e-8 or less.\n","print('Testing conv_backward function')\n","print('dx error: ', rel_error(dx, dx_num))\n","print('dw error: ', rel_error(dw, dw_num))\n","print('db error: ', rel_error(db, db_num))"]},{"cell_type":"markdown","metadata":{"id":"yO0aassu1oA8"},"source":["# Exercise 2: Pooling\n","## Exercise 2.1: forward pass of (max / average) pooling\n","\n","\n","<table>\n","<td>\n","<img src=\"https://github.com/csaybar/DLcoursera/blob/master/Convolutional%20Neural%20Networks/week01/images/max_pool1.png?raw=1\" style=\"width:500px;height:300px;\">\n","<td>\n","\n","<td>\n","<img src=\"https://github.com/csaybar/DLcoursera/blob/master/Convolutional%20Neural%20Networks/week01/images/a_pool.png?raw=1\" style=\"width:500px;height:300px;\">\n","<td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"9ALWMKuZ1oA9"},"source":["### To do:\n","- Implement `Pooling.forward` function in `HW_YourAnswer.py` file <br>\n","- In pooling operation, we assume that the pooling area is square (pool_height == pool_width)\n","\n","**Hint**: Tricks used in convolution layer can also be similarly applied.\n","\n","Here, you do not have to consider the efficiency. \n","\n","However, if you could implement more efficiently, you have a chance to get a bonus point. (It is not mandatory)\n","\n","Refer to Exercise 4 for more information on earning a bonus point.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1697618449294,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"EmihMH9Z1oA9","outputId":"0e669ccd-47cb-448d-9d63-b93a772317b5"},"outputs":[],"source":["from HW_YourAnswer import *\n","x_shape = (2, 4, 4, 3)\n","x = np.linspace(-0.3, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n","pool_param = {'pool_size': 2, 'stride': 2, 'pool_type': \"max\"}\n","\n","out, _ = Pooling.forward(x, pool_param)\n","\n","correct_out = np.array([[[[-0.18947368, -0.18210526, -0.17473684],\n","   [-0.14526316, -0.13789474, -0.13052632]],\n","  [[-0.01263158, -0.00526316,  0.00210526],\n","   [ 0.03157895,  0.03894737,  0.04631579]]],\n"," [[[ 0.16421053,  0.17157895,  0.17894737],\n","   [ 0.20842105,  0.21578947,  0.22315789]],\n","  [[ 0.34105263,  0.34842105,  0.35578947],\n","   [ 0.38526316,  0.39263158,  0.4       ]]]])\n","\n","# Compare your output with ours. Difference should be on the order of e-7 or less.\n","print('Testing max pooling function:')\n","print('difference: ', rel_error(out, correct_out))\n","\n","pool_param = {'pool_size': 2, 'stride': 2, 'pool_type': \"avg\"}\n","\n","out, _ = Pooling.forward(x,  pool_param)\n","correct_out = np.array([[[[-0.24473684, -0.23736842, -0.23      ],\n","   [-0.20052632, -0.19315789, -0.18578947]],\n","  [[-0.06789474, -0.06052632, -0.05315789],\n","   [-0.02368421, -0.01631579, -0.00894737]]],\n"," [[[ 0.10894737,  0.11631579,  0.12368421],\n","   [ 0.15315789,  0.16052632,  0.16789474]],\n","  [[ 0.28578947,  0.29315789,  0.30052632],\n","   [ 0.33,        0.33736842,  0.34473684]]]])\n","# Compare your output with ours. Difference should be on the order of e-7 or less.\n","print('Testing avg pooling function:')\n","print('difference: ', rel_error(out, correct_out))"]},{"cell_type":"markdown","metadata":{"id":"PQ2XzLgX1oA-"},"source":["## Exercise 2.2: backward pass of (max / average) pooling\n","\n","### To do:\n","- Implement `Pooling.backward` function in `HW_YourAnswer.py` file <br>\n","\n","Here, you do not have to consider the efficiency.\n","\n","However, if you could implement more efficiently, you have a chance to get a bonus point. (It is not mandatory)\n","\n","Refer to Exercise 4 for more information on earning a bonus point."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":808,"status":"ok","timestamp":1697618450101,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"lzYnFv7J1oA-","outputId":"6deafc1e-db64-4db9-f4eb-e092fa22330e"},"outputs":[],"source":["np.random.seed(231)\n","x = np.random.randn(3, 8, 8, 2)\n","dout = np.random.randn(3, 4, 4, 2)\n","\n","pool_param = {'pool_size': 2, 'stride': 2, 'pool_type': \"max\"}\n","\n","\n","dx_num = eval_numerical_gradient_array(lambda x: Pooling.forward(x, pool_param)[0], x, dout)\n","\n","out, cache = Pooling.forward(x, pool_param)\n","dx = Pooling.backward(dout, cache)\n","\n","# Your error should be on the order of e-12\n","print('Testing max pooling function:')\n","print('dx error: ', rel_error(dx, dx_num))\n","\n","pool_param = {'pool_size': 2, 'stride': 2, 'pool_type': \"avg\"}\n","dx_num = eval_numerical_gradient_array(lambda x: Pooling.forward(x, pool_param)[0], x, dout)\n","\n","out, cache = Pooling.forward(x,pool_param)\n","dx = Pooling.backward(dout, cache)\n","\n","# Your error should be on the order of e-11\n","print('Testing avg pooling function:')\n","print('dx error: ', rel_error(dx, dx_num))"]},{"cell_type":"markdown","metadata":{"id":"48mjUCZ21oA-"},"source":["# Exercise 3: Batch Normalization for CNN\n","\n","Normally, batch-normalization accepts inputs of shape `(N, D)` and produces outputs of shape `(N, D)`, where we normalize across the minibatch dimension `N`.\n","\n","For data coming from convolutional layers, batch normalization needs to accept inputs of shape `(N, H, W, C)` and produce outputs of shape `(N, H, W, C)` where the `N` dimension gives the minibatch size and the `(H, W)` dimensions give the spatial size of the feature map.\n","\n","If the feature map was produced using convolutions, then we expect every feature channel's statistics e.g. mean, variance to be relatively consistent both between different images, and different locations within the same image -- after all, every feature channel is produced by the same convolutional filter!\n","\n","Therefore, spatial batch normalization computes a mean and variance for each of the `C` feature channels by computing statistics over the minibatch dimension `N` as well the spatial dimensions `H` and `W`.\n","\n","As we learned in Lecture 8 (slide 35), a single fixed empirical mean/std obtained during training is used in the test time.\n","\n","The empirical mean/std (running_mean, running_std) is calculated in the training time as :\n","\n","$u_{moving} =  \\alpha u_{moving} + (1-\\alpha) u_{B}$\n","\n","$\\sigma_{moving}^2  = \\alpha \\sigma_{moving}^2 + (1-\\alpha) \\sigma_{B}^2$\n","\n","where where $\\alpha$ is momentum and $u_{B}, \\sigma_{B}^2$ is calculated mean,var from the current mini-batch\n","\n","\n","[Sergey Ioffe and Christian Szegedy, \"Batch Normalization: Accelerating Deep Network Training by Reducing\n","Internal Covariate Shift\", ICML 2015.](https://arxiv.org/abs/1502.03167)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1697618450101,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"QDJ0msj_1oA-","outputId":"2f66da4d-a551-43d9-fa65-879601fa5433"},"outputs":[],"source":["display.Image(\"figures/bn.png\",width=400,height=400)"]},{"cell_type":"markdown","metadata":{"id":"o6N-wkVx1oA-"},"source":["## Exercise 3.1: forward pass of spatial batch normalization\n","\n","### To do:\n","- Implement `BatchNorm.forward` function in `HW_YourAnswer.py` file <br>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1697618450101,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"nNYtQSxS1oA_","outputId":"9203549c-c5e0-478d-fad2-50ebdd1178ac"},"outputs":[],"source":["np.random.seed(231)\n","\n","# Check the training-time forward pass by checking means and variances\n","# of features both before and after spatial batch normalization.\n","N, H, W, C = 7, 4, 4, 3\n","x = 8 * np.random.randn(N, H, W, C) + 4\n","\n","print('Before spatial batch normalization:')\n","print('  shape: ', x.shape)\n","print('  means: ', x.mean(axis=(0, 1, 2)))\n","print('  stds: ', x.std(axis=(0, 1, 2)))\n","\n","# Means should be close to zero and stds close to one\n","gamma, beta = np.ones(C), np.zeros(C)\n","bn_param = {'mode': 'train'}\n","out, _ = BatchNorm.forward(x, gamma, beta, bn_param)\n","print('After spatial batch normalization:')\n","print('  shape: ', out.shape)\n","print('  means: ', out.mean(axis=(0, 1, 2)))\n","print('  stds: ', out.std(axis=(0, 1, 2)))\n","\n","# Means should be close to beta and stds close to gamma\n","gamma, beta = np.asarray([1, 2, 4]), np.asarray([8, 4, 3])\n","out, _ = BatchNorm.forward(x, gamma, beta, bn_param)\n","print('After spatial batch normalization (nontrivial gamma, beta):')\n","print('  shape: ', out.shape)\n","print('  means: ', out.mean(axis=(0, 1, 2)))\n","print('  stds: ', out.std(axis=(0, 1, 2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1697618450101,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"fWu3q9861oA_","outputId":"7ad0fe7d-8809-4277-ff1f-998a09713efc"},"outputs":[],"source":["np.random.seed(231)\n","# Check the test-time forward pass by running the training-time\n","# forward pass many times to warm up the running averages, and then\n","# checking the means and variances of activations after a test-time\n","# forward pass.\n","N, H, W, C = 10, 11, 12, 6\n","bn_param = {'mode': 'train'}\n","gamma = np.ones(C)\n","beta = np.zeros(C)\n","for t in range(50):\n","  x = 2.3 * np.random.randn(N, H, W, C) + 13\n","  BatchNorm.forward(x, gamma, beta, bn_param)\n","bn_param['mode'] = 'test'\n","x = 2.3 * np.random.randn(N, H, W, C) + 13\n","a_norm, _ = BatchNorm.forward(x, gamma, beta, bn_param)\n","\n","# Means should be close to zero and stds close to one, but will be\n","# noisier than training-time forward passes.\n","print('After spatial batch normalization (test-time):')\n","print('  means: ', a_norm.mean(axis=(0, 1, 2)))\n","print('  stds: ', a_norm.std(axis=(0, 1, 2)))"]},{"cell_type":"markdown","metadata":{"id":"aZjz52h51oA_"},"source":["## Exercise 3.2: backward pass of spatial batch normalization\n","\n","### To do:\n","- Implement `BatchNorm.backward` function in `HW_YourAnswer.py` file <br>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":296,"status":"ok","timestamp":1697618450389,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"EtYjlytt1oA_","outputId":"1f7e19d0-f84a-4bef-87e6-8da05dca9fd7"},"outputs":[],"source":["np.random.seed(230)\n","N, H, W, C = 2, 4, 5, 3\n","x = 5 * np.random.randn(N, H, W, C) + 13\n","gamma = np.random.randn(C)\n","beta = np.random.randn(C)\n","dout = np.random.randn(N, H, W, C)\n","\n","bn_param = {'mode': 'train'}\n","fx = lambda x: BatchNorm.forward(x, gamma, beta, bn_param)[0]\n","fg = lambda gamma: BatchNorm.forward(x, gamma, beta, bn_param)[0]\n","fb = lambda beta: BatchNorm.forward(x, gamma, beta, bn_param)[0]\n","\n","dx_num = eval_numerical_gradient_array(fx, x, dout)\n","da_num = eval_numerical_gradient_array(fg, gamma, dout)\n","db_num = eval_numerical_gradient_array(fb, beta, dout)\n","\n","#You should expect errors of magnitudes between 1e-12~1e-06\n","_, cache = BatchNorm.forward(x, gamma, beta, bn_param)\n","dx, dgamma, dbeta = BatchNorm.backward(dout, cache)\n","print('dx error: ', rel_error(dx_num, dx))\n","print('dgamma error: ', rel_error(da_num, dgamma))\n","print('dbeta error: ', rel_error(db_num, dbeta))"]},{"cell_type":"markdown","metadata":{"id":"BRZSXnmN1oA_"},"source":["# Exercise 4:  Convolutional Neural Network\n","\n","Now, we can put the layers implemented above together into a simple convolutional network.\n","\n","Complete the implementation of the `numpy_CNN` class in `HW_YourAnswer_cnn.py` .\n","\n","Remember you can use pre-defined layers (already imported for you) defined in  `helper_functions.py` in your implementation.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_CLF1d9c1oA_"},"source":["## Data preprocessing\n","\n","We will use the CIFAR10 dataset as we did in HW-1\n","\n","CIFAR10 dataset is composed of 50000 train data and 10000 test data. For our exercises, we will selectively use subsets of these images: 10,000 for training, 1,000 for validation, and 1,000 for testing."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1697618450684,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"gifyIehW1oA_","outputId":"0db9d146-edee-4fad-c167-d60173004b67"},"outputs":[],"source":["data = get_CIFAR10_data()\n","\n","print('Train data shape: ', data[\"X_train\"].shape)\n","print('Train labels shape: ', data['y_train'].shape)\n","print('Validation data shape: ', data['X_val'].shape)\n","print('Validation labels shape: ', data['y_val'].shape)\n","print('Test data shape: ', data['X_test'].shape)\n","print('Test labels shape: ', data['y_test'].shape)"]},{"cell_type":"markdown","metadata":{"id":"C28u6XeL1oA_"},"source":["## Sanity Check Loss\n","After you build a new network, one of the first things you should do is to sanity check the loss. When we add regularization, the loss should go up slightly."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2388,"status":"ok","timestamp":1697618453070,"user":{"displayName":"변재석","userId":"03745172202739284748"},"user_tz":-540},"id":"NLOoK6Hp1oBA","outputId":"8d360998-7bb5-4a00-ecb5-5557ab496966"},"outputs":[],"source":["model = numpy_CNN()\n","\n","N = 50\n","X = np.random.randn(N, 32, 32, 3)\n","y = np.random.randint(10, size=N)\n","\n","loss, grads = model.loss(X, y)\n","print('Initial loss (no regularization): ', loss)\n","\n","model.reg = 0.5\n","loss, grads = model.loss(X, y)\n","print('Initial loss (with regularization): ', loss)"]},{"cell_type":"markdown","metadata":{"id":"leuLq16C1oBA"},"source":["\n","## Train the Network\n","By training the three-layer convolutional network for one epoch, you could achieve greater than 35% accuracy on the training set.\n","\n","However, if you naively implement the backward pass of convolution layer and the forward/backward pass of pooling layer without any consideration of computational efficiency,\n","\n","it would take **several hours** to train this simple network (under the default Colab setting). Nevertheless, as long as your code is executable, you'll secure a point, regardless of how long it takes.\n","\n","### Bonus point (efficient implementation)\n","\n","Achieving a training time of less than 10 minutes for a single epoch (under the default Colab setting) will earn you a bonus point. Note that this is not mandatory.\n","\n","For this, you need to consider the efficient implementation of the backward pass of convolution layer and the forward/backward pass of pooling layer (`Conv.backward`,`Pooling.forward`, `Pooling.backward`).\n","\n","Specifically, if you can avoid the for-loop for the number of filter ('F') in `Conv.backward` and  for-loop for the channel dimension ('C') in `Pooling.forward` and `Pooling.backward`, you could achieve a training time of less than 10 minutes.\n","\n","While further optimizations can be achieved by eliminating other loops, you do not have to consider other options in this assignment.\n","\n","- Backward pass of convolution layer: avoids looping over the number of filter (F)\n","    - Similar trick introduced in Exercise 1.2 can also be applied.\n","\n","- Forward / Backward pass of pooling layer: avoids looping over the channel dimension (C)\n","    - Utilize broadcasting capabilities of Numpy. \n","\n","If you choose to implement this, make your changes in the `Conv.backward`, `Pooling.forward`, `Pooling.backward` functions within the `HW_YourAnswer.py` file."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5jIp49L1oBA","outputId":"a3ec1abc-7c24-4f61-bd01-909f26fc2d60","scrolled":false},"outputs":[],"source":["from time import time\n","\n","model = numpy_CNN(weight_scale=0.001, hidden_dim=500, reg=0.001)\n","t0 = time()\n","solver = Solver(\n","    model,\n","    data,\n","    num_epochs=1,\n","    batch_size=50,\n","    optim_config={'learning_rate': 1e-3,},\n","    verbose=True,\n","    print_every=20\n",")\n","solver.train()\n","t1 = time()\n","\n","print('Trainig time: %fs' % (t1 - t0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B7LGeGUP1oBA","test":"full_data_train_accuracy"},"outputs":[],"source":["# Print final training accuracy.\n","print(\n","    \"Full data training accuracy:\",\n","    solver.check_accuracy(data['X_train'], data['y_train'])\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-WkhONUQ1oBA","test":"full_data_validation_accuracy"},"outputs":[],"source":["# Print final validation accuracy.\n","print(\n","    \"Full data validation accuracy:\",\n","    solver.check_accuracy(data['X_val'], data['y_val'])\n",")"]},{"cell_type":"markdown","metadata":{"id":"eSNSZvNx1oBA"},"source":["## Visualize Filters\n","You can visualize the first-layer convolutional filters from the trained network by running the following:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68rLU5x-1oBA"},"outputs":[],"source":["from utils import visualize_grid\n","\n","grid = visualize_grid(model.params['W1'])\n","plt.imshow(grid.astype('uint8'))\n","plt.axis('off')\n","plt.gcf().set_size_inches(5, 5)\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"nbformat":4,"nbformat_minor":0}
