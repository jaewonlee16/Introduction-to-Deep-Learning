{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: TwoLayer Network (PyTorch)\n",
    "Many codes for research papers are based in PyTorch or Tensorflow. These libraries provide automatic differential system and allow tensor computation with strong acceleration via GPU, which helps to build and train Deep learning model.[1]  However, the adoption of PyTorch was extremely rapid and, in just a few years, grew to use in almost 80% of papers that use either PyTorch or TensorFlow. [2]\n",
    "\n",
    "In this assignment, we will learn how to use __PyTorch__ __framework__ by training Twolayer Network which was already done in HW1. The model structure is same with the structure we've already done in HW1.\n",
    "\n",
    "[1] https://en.wikipedia.org/wiki/PyTorch\n",
    "\n",
    "[2] https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2023/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's check if you are properly using GPU\n",
    "- Ouput should be 'True'\n",
    "- If not, please follow the instructions in ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('GPU available?:', use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's mount your drive directory to current notebook and change the system directory to your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/your_working_dir')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/your_working_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import *\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Content (CIFAR10)\n",
    "we will use the CIFAR10 dataset, which was already used for HW1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, Y_tr, X_te, Y_te, mean_img = get_CIFAR10_data()\n",
    "print ('Train data shape : %s,  Train labels shape : %s' % (X_tr.shape, Y_tr.shape))\n",
    "print ('Test data shape : %s,  Test labels shape : %s' % (X_te.shape, Y_te.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "\n",
    "images_index = np.int32(np.round(np.random.rand(18,)*10000,0))\n",
    "\n",
    "fig, axes = plt.subplots(3, 6, figsize=(18, 6),\n",
    "                         subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.05)\n",
    "\n",
    "for ax, idx in zip(axes.flat, images_index):\n",
    "    img = (X_tr[idx,:3072].reshape(32, 32, 3) + mean_img.reshape(32, 32, 3))\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(class_names[Y_tr[idx]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_tr, Y_tr, X_te, Y_te = torch.tensor(X_tr), torch.tensor(Y_tr), torch.tensor(X_te), torch.tensor(Y_te)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Dataset\n",
    "train_ds = TensorDataset(X_tr, Y_tr)\n",
    "test_ds = TensorDataset(X_te, Y_te)\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models with PyTorch\n",
    "\n",
    "There are two important functions to know when we build up models using PyTorch library : __init__() and __forward__().\n",
    "\n",
    "__init__() sets up the networkâ€™s structure by defining the layers, while __forward__() specifies how the data flows through the network. Both methods are required to create a neural network in PyTorch and serve different purposes. [1]\n",
    "\n",
    "1. __init__()\n",
    "\n",
    "__init__ is a constructor method used to initialize the parameters of the network. It is executed when an object of the class is created. For example, in PyTorch, this method is used to define the layers of the network, such as convolutional layers, linear layers, activation functions, etc.\n",
    "\n",
    "2. __forward__()\n",
    "\n",
    "forward is the method that defines the forward pass of the neural network. This method takes the input data and passes it through the layers of the network to produce the output. This method is executed whenever the model is called to make a prediction or to compute the loss during training.\n",
    "\n",
    "For further details, please read [2]\n",
    "\n",
    "[1] https://discuss.pytorch.org/t/what-is-the-difference-init-and-forward-in-a-network-model/173907\n",
    "\n",
    "[2] https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "- Implement missing codes in `Building Models with Pytorch`.\n",
    "- Design guide (__Strictly requried__)\n",
    "    - Follow the structure of `TwolayerNet` implemented in `HW_YourAnswer.py`\n",
    "        - \" Input => Fully Connected => ReLU => Fully Connected => OutputLayer \"\n",
    "    - Hidden dimension : 1024\n",
    "\n",
    "- Find and use torch modules for required structure(softmax, relu, ..). (https://pytorch.org/docs/stable/nn.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# ========================================== WRITE YOUR CODE ========================================== #\n",
    "\n",
    "# Instructions: \n",
    "#     - Implement TwoLayerNet using torch module.\n",
    "#     - Please read [2] (https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html) for further details\n",
    "#     - The 'TwolayerNet' class should 2 functions : 1) __init__ 2) forward\n",
    "#     - Model Structure would be like\n",
    "#       \" Input => Fully Connected => ReLU => Fully Connected => OutputLayer \"\n",
    "    \n",
    " # ======================================================================================================\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Hyperparameters\n",
    "Here, we manually set hyperparameters(epochs, lr, ..) that are used for training the model. Hyper-parameters are one of the important factor to train a model up to targeting performance. Batch size which is defined above is also an important hyper-parameter for training Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "lr = 0.1\n",
    "weight_decay = 0.0001\n",
    "\n",
    "model = TwolayerNet().cuda()\n",
    "optimizer = torch.optim.SGD(params = model.parameters(), lr = lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    test_correct = 0\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # train\n",
    "    for data in train_loader:\n",
    "        img, label = data\n",
    "\n",
    "        img = img.type(torch.FloatTensor).cuda()\n",
    "        label = label.type(torch.LongTensor).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(img)\n",
    "\n",
    "        train_correct += (pred.argmax(dim = 1) == label).sum().item()\n",
    "        \n",
    "        loss = loss_fn(pred, label)\n",
    "        epoch_loss += loss.item() * batch_size\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # eval\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            img, label = data\n",
    "            img = img.type(torch.FloatTensor).cuda()\n",
    "            label = label.cuda()\n",
    "            pred = model(img.flatten(1))\n",
    "\n",
    "            test_correct += (pred.argmax(dim = 1) == label).sum().item()\n",
    "    \n",
    "    train_acc.append(train_correct / len(train_loader.dataset))\n",
    "    test_acc.append(test_correct/len(test_loader.dataset))\n",
    "      \n",
    "    print(f'Epoch: {epoch}, Training acc: {train_correct / len(train_loader.dataset):.3f}, Test acc : {test_correct / len(test_loader.dataset):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct = 0\n",
    "for data in test_loader:\n",
    "    img, label = data\n",
    "    img = img.type(torch.FloatTensor).cuda()\n",
    "    label = label.cuda()\n",
    "    pred = model(img.flatten(1))\n",
    "\n",
    "    n_correct += (pred.argmax(dim = 1) == label).sum().item()\n",
    "\n",
    "print(f\"Final Test Accuracy: {n_correct / len(test_loader.dataset):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plot(train_acc,test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "albef",
   "language": "python",
   "name": "albef"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
